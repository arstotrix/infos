{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 2  BM5    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    " \n",
    "# инициализируем\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# составляем корпус документов\n",
    "corpus = [\n",
    "  'слово1 слово2 слово3',\n",
    "  'слово2 слово3',\n",
    "  'слово1 слово2 слово1',\n",
    "  'слово4'\n",
    "]\n",
    "\n",
    "# считаем\n",
    "X = vectorizer.fit_transform(corpus)\n",
    " \n",
    "# получится следующая структура:\n",
    "#        |  слово1  |  слово2  |  слово3  |  слово4\n",
    "# текст1 |   0.6    |    0.5   |   0.6    |    0\n",
    "# текст2 |   0      |    0.6   |   0.8    |    0\n",
    "# текст3 |   0.9    |    0.4   |   0      |    0\n",
    "# текст4 |   0      |    0     |   0      |    1\n",
    " \n",
    "# чтобы получить сгенерированный словарь, из приведенной структуры TfidfVectorizer\n",
    "# порядок совпадает с матрицей\n",
    "vectorizer.get_feature_names()  # ['слово1', 'слово2', 'слово3', 'слово4']\n",
    " \n",
    "# чтобы узнать индекс токена в словаре\n",
    "vectorizer.vocabulary_.get('слово3') # вернет 2\n",
    " \n",
    "# показать матрицу\n",
    "X.toarray()\n",
    " \n",
    "# теперь можно быстро подсчитать вектор для нового документа\n",
    "new_doc = vectorizer.transform(['слово1 слово4 слово4']).toarray()  # результат [[0.36673901, 0, 0, 0.93032387]]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{TF(q_i,D)*(k+1)}{TF(q_i,D)+k(1-b+b\\frac{l(d)}{avgdl})} $$ \n",
    "где   \n",
    ">$TF(q_i,D)$ - частота слова $q_i$ в документе $D$      \n",
    "$l(d)$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k$ и $b$ — свободные коэффициенты, обычно их выбирают как $k$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ - это модернизированная версия IDF: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k = 2.0\n",
    "b = 0.75\n",
    "\n",
    "\n",
    "def bm25() -> float:\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 1__:    \n",
    "Реализуйте поиск с метрикой *TF-IDF* через умножение матрицы на вектор.\n",
    "Что должно быть в реализации:\n",
    "- проиндексированная база, где каждый документ представлен в виде вектора TF-IDF\n",
    "- функция перевода входяшего запроса в вектор по метрике TF-IDF\n",
    "- ранжирование докуменов по близости к запросу по убыванию\n",
    "\n",
    "В качестве корпуса возьмите корпус вопросов в РПН по Covid2019. Он состоит из:\n",
    "> файл **answers_base.xlsx** - база ответов, у каждого ответа есть его номер, тематика и примеры вопросов, которые могут быть заданы к этому ответу. Сейчас проиндексировать надо именно примеры вопросов в качестве документов базы. Понимаете почему?\n",
    "\n",
    "> файл **queries_base.xlsx** - вопросы юзеров, к каждому из которых проставлен номер верного ответа из базы. Разделите эти вопросы в пропорции 70/30 на обучающую (проиндексированную как база) и тестовую (как запросы) выборки. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача 2__:    \n",
    "Аналогичная задаче1 с другой метрикой \n",
    "\n",
    "Реализуйте поиск с метрикой *BM25* через умножение матрицы на вектор. Что должно быть в реализации:\n",
    "\n",
    "- проиндексированная база, где каждый документ представлен в виде вектора BM25\n",
    "- функция перевода входяшего запроса в вектор по метрике BM25\n",
    "- ранжирование докуменов по близости к запросу по убыванию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
