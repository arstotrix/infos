{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ранжирование\n",
    "\n",
    "Будем ранжировать разные данные с помощью XGBoost. <br>\n",
    "В XGBoost используется алгоритм LambdaMART, который осуществляет pairwise ранжирование.\n",
    "\n",
    "## Пример\n",
    "\n",
    "Взят [отсюда](https://github.com/dmlc/xgboost/blob/master/demo/rank/rank_sklearn.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные: датасет LETOR 4.0 MQ2008 - бенчмарк для ранжирования.\n",
    "\n",
    "Данные представлены так:\n",
    "* один объект - это запрос, один документ к нему (набор каких-то признаков) и одна метка релевантности (target)\n",
    "* соответственно, для одного и того же запроса может быть несколько объектов\n",
    "* информация, что, например, какие-то пять объектов относятся к одному запросу, содержится в отдельной структуре \"groups\" и передается в обучение\n",
    "\n",
    "Читаем объекты и таргеты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_svmlight_file(\"data/mq2008.train\")\n",
    "x_valid, y_valid = load_svmlight_file(\"data/mq2008.vali\")\n",
    "x_test, y_test = load_svmlight_file(\"data/mq2008.test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные:\n",
    "* в обучении 9630 объектов\n",
    "* 46 признаков\n",
    "* релевантность оценивается по трехбалльной шкале"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9630, 46)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.007477, 0.      , 1.      , 0.      , 0.00747 , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.471076, 0.      ,\n",
       "         1.      , 0.      , 0.477541, 0.00512 , 0.      , 0.571429,\n",
       "         0.      , 0.004806, 0.768561, 0.727734, 0.716277, 0.582061,\n",
       "         0.      , 0.      , 0.      , 0.      , 0.780495, 0.962382,\n",
       "         0.999274, 0.961524, 0.      , 0.      , 0.      , 0.      ,\n",
       "         0.797056, 0.697327, 0.721953, 0.582568, 0.      , 0.      ,\n",
       "         0.      , 0.      , 0.      , 0.007042]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_train[0].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0, 1.0, 2.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем информацию о группах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_train = []\n",
    "with open(\"data/mq2008.train.group\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        group_train.append(int(line.split(\"\\n\")[0]))\n",
    "\n",
    "group_valid = []\n",
    "with open(\"data/mq2008.vali.group\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        group_valid.append(int(line.split(\"\\n\")[0]))\n",
    "\n",
    "group_test = []\n",
    "with open(\"data/mq2008.test.group\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    for line in data:\n",
    "        group_test.append(int(line.split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как устроена информация о группах:\n",
    "* количество групп отражает информацию о количестве запросов\n",
    "* каждое число обозначает количество последовательных объектов, которые в эту группу объединяются\n",
    "* из предыдущего пункта следует, что в X объекты нельзя перемешивать\n",
    "* если просуммировать все числа в списке групп, получим число объектов из X\n",
    "\n",
    "Для чего нужны группы? <br>\n",
    "Для того, чтобы в обучении не сравнивать доки из разных групп (разных запросов) между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471 9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 8, 8, 8, 8, 16, 8, 118, 16, 8]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(group_train), sum(group_train))\n",
    "group_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель. <br>\n",
    "С помощью `eval_set` можем контролировать обучение, но это необязательный параметр, можно обучить и без валидации. <br>\n",
    "В параметре `objective` можно задать три опции: `rank:ndcg`, `rank:pairwise`, `rank:map`. `ndcg` и `map` регулияруют попарный лосс с помощью подсчета соответствующих метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval_0-map:0.71552\n",
      "[1]\teval_0-map:0.72606\n",
      "[2]\teval_0-map:0.72795\n",
      "[3]\teval_0-map:0.73352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=1, gamma=1.0, gpu_id=-1,\n",
       "          importance_type='gain', interaction_constraints='', learning_rate=0.1,\n",
       "          max_delta_step=0, max_depth=6, min_child_weight=0.1, missing=nan,\n",
       "          monotone_constraints='()', n_estimators=4, n_jobs=0,\n",
       "          num_parallel_tree=1, objective='rank:ndcg', random_state=0,\n",
       "          reg_alpha=0, reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "          tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'objective': 'rank:ndcg', 'learning_rate': 0.1,\n",
    "          'gamma': 1.0, 'min_child_weight': 0.1,\n",
    "          'max_depth': 6, 'n_estimators': 4}\n",
    "\n",
    "model = xgb.sklearn.XGBRanker(**params)\n",
    "model.fit(x_train, y_train, group_train, verbose=True,\n",
    "          eval_set=[(x_valid, y_valid)], eval_group=[group_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим предсказание на тестовом сете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем качество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 0\n",
    "grouped_pred = []\n",
    "grouped_target = []\n",
    "\n",
    "for group_n in group_test:\n",
    "    grouped_pred.append(pred[start_idx:start_idx+group_n])\n",
    "    grouped_target.append(y_test[start_idx:start_idx+group_n])\n",
    "    start_idx += group_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5052327963105946"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([\n",
    "    ndcg_score([grouped_target[i]], [grouped_pred[i]])\n",
    "    for i in range(len(grouped_target))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар и дз\n",
    "Сделать и улучшить любую ML-модель на ваших проектных данных (просто клф, бленд, ранжирование, что-то что вы придумали сами...), используя любые признаки, какие захотите. Оцениваться будут:\n",
    "* факт выполнения задания :)\n",
    "* корректность кода (чтобы код не падал) и отсутствие логических ошибок (e.g. затестили на трейне)\n",
    "* итеративность улучшения (например взяли один сет признаков, показали качество; потом добавили / подкрутили / использовали другую модель, показали качество...)\n",
    "* креативность признаков\n",
    "* аккуратность ноутбука\n",
    "\n",
    "Дедлайн: 15 октября"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
