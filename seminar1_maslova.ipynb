{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pymorphy2\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "json_texts = {}\n",
    "texts = []\n",
    "sting = string.punctuation + '1234567890qwertyuiopasdfghjklzxcvbnm'\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "curr_dir = os.path.join(curr_dir, 'friends-data')\n",
    "folders = os.listdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(filepath, texts, json_texts):\n",
    "    words = {}\n",
    "    with open(filepath, 'r', encoding = 'UTF-8') as f:   \n",
    "        text = f.read().lower()\n",
    "    text = text[1:]\n",
    "    for s in sting:\n",
    "        text = text.replace(s,'')\n",
    "    pretext = nltk.word_tokenize(text) \n",
    "    for i, p in enumerate(pretext):   \n",
    "        pretext[i] = morph.parse(p)[0][2] \n",
    "        p = pretext[i]\n",
    "        if p not in words:\n",
    "            words[p] = {}\n",
    "            words[p][filepath] = 1\n",
    "        else:\n",
    "            words[p][filepath] += 1\n",
    "    line = ' '.join(pretext) \n",
    "    \n",
    "    texts.append(line)\n",
    "    json_texts.update(words)\n",
    "    \n",
    "    return texts, json_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in folders:\n",
    "    localpath = os.path.join(curr_dir, folder)\n",
    "    files = os.listdir(localpath)\n",
    "    for file in files:\n",
    "        filepath = os.path.join(localpath, file)   \n",
    "        texts, json_texts = preprocess(filepath, texts, json_texts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)\n",
    "vectorizer.get_feature_names()  \n",
    " \n",
    "\"\"\"# чтобы узнать индекс токена в словаре\n",
    "vectorizer.vocabulary_.get('слово3') # вернет 2\n",
    " \n",
    "# показать матрицу\n",
    "X.toarray()\n",
    " \n",
    "# теперь можно быстро подсчитать вектор для нового документа\n",
    "vectorizer.transform([\"слово1 слово4 слово4\"])  # результат [[1 0 0 2]]\n",
    " \n",
    "# чтобы узнать количественное вхождение каждого слова:\n",
    "matrix_freq = np.asarray(X.sum(axis=0)).ravel()\n",
    "final_matrix = np.array([np.array(vectorizer.get_feature_names()), matrix_freq])\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
